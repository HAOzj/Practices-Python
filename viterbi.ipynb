{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**POS tagger**  \n",
    "POS tagger的作用是给文本的每个单词赋予一个词性(POS, Part Of Speech).词性可以提供关于所在词和上下文的信息.比如动词后一般跟名词.词性信息可以帮助语法分析或者命名实体识别等.    \n",
    "  \n",
    "给定一组词  $\\{w_i\\}_{i=1}^l$,POS tagger求 $ argmax _{ \\{tag_i\\}_{i=i}^l }   P( \\{tag_i\\}_{i=i}^l | \\{w_i\\}_{i=1}^l)$，也就是该组词下,出现概率最大的一组POS tags.  \n",
    "\n",
    "根据贝叶斯法则, $ P( \\{tag_i\\}_{i=i}^l | \\{w_i\\}_{i=1}^l  =  \\frac {P( \\{w_i\\}_{i=1}^l|\\{tag_i\\}_{i=i}^l ) *   P( \\{tag_i\\}_{i=i}^l)} {P(\\{w_i\\}_{i=1}^l)}    $.  \n",
    "\n",
    "为了简化问题，我们扔掉分母,最大化$P( \\{w_i\\}_{i=1}^l|\\{tag_i\\}_{i=i}^l ) *   P( \\{tag_i\\}_{i=i}^l)$  \n",
    " \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HMM(Hidden Markov Model)隐马模型**  \n",
    "\n",
    "HMM对上述问题进行了两个方面的简化,  \n",
    "1. tags序列的一阶markov性,也就是第i个tag的概率只依赖于第i-1个tag.那么$P{\\{tag_i\\}_{i=i}^l} =  \\prod_{i=1}^{l} P(tag_i|tag_{i-1})$  \n",
    "2. 每个$w_i$的概率只依赖于该词的tag,和周围的词无关.也就是$P(\\{w_i\\}_{i=1}^l) = \\prod_{i=1}^{l}P(w_i|tag_i)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P( \\{w_i\\}_{i=1}^l|\\{tag_i\\}_{i=i}^l ) *   P( \\{tag_i\\}_{i=i}^l) =  \\prod_{i=1}^{l} P(tag_i|tag_{i-1}) P(w_i|tag_i) $  \n",
    "1. $P( w_i|tag_i) $叫做emission(产生概率),表示一种POS tag生成一个词的概率;\n",
    "2. $P( tag_i|tag_{i-1})$ 叫做transition(转移概率)，表示从POS tag的一种到另一种的概率 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Viterbi算法是求出隐马模型最优解的方法**  \n",
    "\n",
    "Viterbi(i, j)记录从第1个词到第j个词概率最大时，第j个词为i词性的概率,通过迭代来实现:  \n",
    "\n",
    "$Viterbi(i,j) =  max_{k=1}^{K} emission(j, i)* Viterbi(k,j-1)* transition[k,j]$  \n",
    "用path(i,j)来记录求Viterbi(i,j)时的k,也就是此时上一个词的词性    \n",
    "\n",
    "为了从后向前获得最优POS tags,  \n",
    "1. t=l,$tag_l^{*} = argmax_{i} Viterbi(i,t)$,也就是从第1个词到最后1个词,概率最大时最后一个词的POS tag.$tag_l^{*}$就是最后一个词的POS tag,    \n",
    "2. $tag_{t-1}^{*} = path(tag_{t+1}^{*},t+1)$.从最后一个词的POS tag来追溯使得它概率最大的倒数第二个词的POS tag.$tag_{t-1}^{*}$就是倒数第二个词的POS tag\n",
    "3. t = t-1，  \n",
    "3. 重复2,3步,直到得到所有词的POS tag  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viterbi算法实现如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词为I, 词性为sub, 概率为0.1036728%\n",
      "词为love, 词性为verb, 概率为0.86394%\n",
      "词为you, 词性为obj, 概率为5.236000000000001%\n",
      "词为love, 词性为verb, 概率为7.48%\n",
      "词为I, 词性为sub, 概率为16.000000000000004%\n",
      "词为b, 词性为b, 概率为100.0%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on the 13th June 2018\n",
    "\n",
    "@author : woshihaozhaojun@sina.com\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def viterbi_algo(text, transition, emission, ind2tag, word2ind ):\n",
    "    '''\n",
    "    pos tagger的viterbi算法\n",
    "    \n",
    "    Args:\n",
    "        text(iterables)      :- 要估计的句子的序列,长度为l\n",
    "        transition(np.array) :- 词性转换矩阵， \n",
    "                                [i,j]元素表示从i词性到j词性的概率，\n",
    "                                维度为[K ,K], K为词性的种类数\n",
    "        emission(np.array)   :- 产生词的概率矩阵,\n",
    "                                [i,k]元素表示i词性生成k词的概率,\n",
    "                                维度为[K, v], v为字典的大小\n",
    "        ind2tag(iterables)   :- 第i个元素为i词性\n",
    "        word2ind(dict)       :- k词为key，序号为value\n",
    "    Returns:\n",
    "        paths(np.array)      :- [i,w]元素表示第w词为i词性时上一个词的词性，\n",
    "                                维度为[n, l]\n",
    "        viterbi(np.array)    :- [i,w]元素表示第w词为i词性的概率,\n",
    "                                维度为[K,l]\n",
    "    \n",
    "    '''\n",
    "    try:\n",
    "        assert transition.shape[0] == transition.shape[1]\n",
    "    except AssertionError:\n",
    "        print(\"转移矩阵不是方阵\")\n",
    "        \n",
    "    try:\n",
    "        assert transition.shape[0] == emission.shape[0]\n",
    "    except AssertionError:\n",
    "        print(\"emission矩阵的行数和词性数不一致\")\n",
    "        \n",
    "    try:\n",
    "        assert len(ind2tag)==transition.shape[0]\n",
    "    except AssertionError:\n",
    "        print(\"ind2tag长度和词性数不一致\")\n",
    "        \n",
    "    cols = len(text) \n",
    "    rows = transition.shape[0]\n",
    "\n",
    "    paths = np.zeros(( rows, cols))\n",
    "    viterbi = np.zeros((rows, cols))\n",
    "    viterbi[0,0] = 1\n",
    "    for j in range(1,cols):\n",
    "        for i in range(rows):\n",
    "            prob = viterbi[:,j-1] *  transition[:,i]* emission[i, word2ind[ text[j]] ] # [cols, 1]\n",
    "            sort = np.argsort(prob)\n",
    "            paths[i,j] =  sort[-1]\n",
    "            viterbi[i,j] = max(prob)\n",
    "            \n",
    "    last =  int(np.argsort(  viterbi[:, j] )[-1]) # 最后一个词的概率最大的行序\n",
    "\n",
    "    print(\n",
    "        \"词为{}, 词性为{}, 概率为{}%\".format( text[-1], ind2tag[last], viterbi[last, j]*100) \n",
    "    )\n",
    "    for j in range(cols-1):\n",
    "        last = int(paths[ last, cols -1 -j    ]) # 上一个词的行序\n",
    "        \n",
    "        print( \n",
    "            \"词为{}, 词性为{}, 概率为{}%\".format( text[-2-j], ind2tag[last],  viterbi[ last  ,cols -2 - j]*100)\n",
    "        )\n",
    "\n",
    "    return paths, viterbi\n",
    "\n",
    "def demo():\n",
    "    text = ['b', 'I', 'love', 'you','love','I'] \n",
    "\n",
    "    ind2tag = ['b', 'sub', 'verb','obj'] # 开头，主语，动词，宾语\n",
    "\n",
    "    transition = np.array( \n",
    "        [\n",
    "            [0, 0.4, 0.6,  0], # 从b到 sub, verb, obj\n",
    "            [0, 0,   0.85, 0.15],\n",
    "            [0, 0.3, 0,    0.7],\n",
    "            [0, 0.3, 0.3,  0.4]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    emission = np.array(\n",
    "        [\n",
    "            [1, 0 , 0, 0],\n",
    "            [0, 0.4, 0, 0.6],\n",
    "            [0, 0.45 , 0.55 , 0],\n",
    "            [0, 0 , 0 , 1]\n",
    "        ]\n",
    "\n",
    "    )\n",
    "\n",
    "    word2ind = {\n",
    "        'b' : 0,\n",
    "        'I' : 1,\n",
    "        'love' :2,\n",
    "        'you' : 3\n",
    "    }\n",
    "    paths, viterbi = viterbi_algo(text, transition, emission, ind2tag,word2ind)\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
